---
title: Video pretraining advances 3D deep learning on chest CT tasks
abstract: Pretraining on large natural image classification datasets such as ImageNet
  has aided model development on data-scarce 2D medical tasks. 3D medical tasks often
  have much less data than 2D medical tasks, prompting practitioners to rely on pretrained
  2D models to featurize slices. However, these 2D models have been surpassed by 3D
  models on 3D computer vision benchmarks since they do not natively leverage cross-sectional
  or temporal information. In this study, we explore whether natural video pretraining
  for 3D models can enable higher performance on smaller datasets for 3D medical tasks.
  We demonstrate video pretraining improves the average performance of seven 3D models
  on two chest CT datasets, regardless of finetuning dataset size, and that video
  pretraining allows 3D models to outperform 2D baselines. Lastly, we observe that
  pretraining on the large-scale out-of-domain Kinetics dataset improves performance
  more than pretraining on a typically-sized in-domain CT dataset. Our results show
  consistent benefits of video pretraining across a wide array of architectures, tasks,
  and training dataset sizes, supporting a shift from small-scale in-domain pretraining
  to large-scale out-of-domain pretraining for 3D medical tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ke24a
month: 0
tex_title: Video pretraining advances 3D deep learning on chest CT tasks
firstpage: 758
lastpage: 774
page: 758-774
order: 758
cycles: false
bibtex_author: Ke, Alexander and Huang, Shih-Cheng and O'Connell, Chloe P and Klimont,
  Michal and Yeung, Serena and Rajpurkar, Pranav
author:
- given: Alexander
  family: Ke
- given: Shih-Cheng
  family: Huang
- given: Chloe P
  family: Oâ€™Connell
- given: Michal
  family: Klimont
- given: Serena
  family: Yeung
- given: Pranav
  family: Rajpurkar
date: 2024-01-23
address:
container-title: Medical Imaging with Deep Learning
volume: '227'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 23
pdf: https://proceedings.mlr.press/v227/ke24a/ke24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
