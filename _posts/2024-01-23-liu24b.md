---
title: '3D Medical Axial Transformer: A Lightweight Transformer Model for 3D Brain
  Tumor Segmentation'
abstract: In recent years, Transformer-based models have gained attention in the field
  of medical image segmentation, with research exploring ways to integrate them with
  established architectures such as Unet. However, the high computational demands
  of these models have led most current approaches to focus on segmenting 2D slices
  of MRI or CT images, which can limit the ability of the model to learn semantic
  information in the depth axis and result in output with uneven edges. Additionally,
  the small size of medical image datasets, particularly those for brain tumor segmentation,
  poses a challenge for training transformer models. To address these issues, we propose
  3D Medical Axial Transformer (MAT), a lightweight, end-to-end model for 3D brain
  tumor segmentation that employs an axial attention mechanism to reduce computational
  demands and self-distillation to improve performance on small datasets. Results
  indicate that our approach, which has fewer parameters and a simpler structure than
  other models, achieves superior performance and produces clearer output boundaries,
  making it more suitable for clinical applications.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24b
month: 0
tex_title: '3D Medical Axial Transformer: A Lightweight Transformer Model for 3D Brain
  Tumor Segmentation'
firstpage: 799
lastpage: 813
page: 799-813
order: 799
cycles: false
bibtex_author: Liu, Cheng and Kiryu, Hisanor
author:
- given: Cheng
  family: Liu
- given: Hisanor
  family: Kiryu
date: 2024-01-23
address:
container-title: Medical Imaging with Deep Learning
volume: '227'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 23
pdf: https://proceedings.mlr.press/v227/liu24b/liu24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
