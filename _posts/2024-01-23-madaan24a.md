---
title: On Sensitivity and Robustness of Normalization Schemes to Input Distribution
  Shifts in Automatic MR Image Diagnosis
abstract: Magnetic Resonance Imaging (MRI) is considered the gold standard of medical
  imaging because of the excellent soft-tissue contrast exhibited in the images reconstructed
  by the MR pipeline, which enables the human radiologist to discern many pathologies
  easily. More recently, Deep Learning (DL) models have also achieved state-of-the-art
  performance in diagnosing multiple diseases using these reconstructed images as
  input. However, the image reconstruction process within the MR pipeline, which requires
  the use of complex hardware and adjustment of a large number of scanner parameters,
  is highly susceptible to the noise of various forms resulting in arbitrary artifacts
  within the images. Furthermore, the noise distribution is not stationary and varies
  within a machine, across machines, and patients, leading to varying artifacts within
  the images. Unfortunately, DL models are quite sensitive to these varying artifacts
  as it leads to changes in the input data distribution between the training and testing
  phases. The lack of robustness of these models against varying artifacts impedes
  their use in medical applications where safety is critical. In this work, we focus
  on improving the generalization performance of these models in the presence of multiple
  varying artifacts that manifest due to the complexity of the MR data acquisition.
  In our experiments, we observe that Batch Normalization (BN), a widely used technique
  during the training of DL models for medical image analysis, is a significant cause
  of performance degradation in these changing environments. As a solution, we propose
  to use other normalization techniques, such as Group Normalization (GN) and Layer
  Normalization (LN), to inject robustness into model performance against varying
  image artifacts. Through a systematic set of experiments, we show that GN and LN
  provide better accuracy for various MR artifacts and distribution shifts.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: madaan24a
month: 0
tex_title: On Sensitivity and Robustness of Normalization Schemes to Input Distribution
  Shifts in Automatic MR Image Diagnosis
firstpage: 1726
lastpage: 1750
page: 1726-1750
order: 1726
cycles: false
bibtex_author: Madaan, Divyam and Sodickson, Daniel and Cho, Kyunghyun and Chopra,
  Sumit
author:
- given: Divyam
  family: Madaan
- given: Daniel
  family: Sodickson
- given: Kyunghyun
  family: Cho
- given: Sumit
  family: Chopra
date: 2024-01-23
address:
container-title: Medical Imaging with Deep Learning
volume: '227'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 23
pdf: https://proceedings.mlr.press/v227/madaan24a/madaan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
