---
title: 'ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised Medical
  Image Representations'
abstract: Self-supervised learning has attracted increasing attention as it learns
  data-driven representation from data without annotations. Vision transformer-based
  autoencoder (ViT-AE) by He et al. (2021) is a recent self-supervised learning technique
  that employs a patch-masking strategy to learn a meaningful latent space. In this
  paper, we focus on improving ViT-AE (nicknamed ViT-AE++) for a more effective representation
  of both 2D and 3D medical images. We propose two new loss functions to enhance the
  representation during the training stage. The first loss term aims to improve self-reconstruction
  by considering the structured dependencies and hence indirectly improving the representation.
  The second loss term leverages contrastive loss to directly optimize the representation
  from two randomly masked views. As an independent contribution, we extended ViT-AE++
  to a 3D fashion for volumetric medical images. We extensively evaluate ViT-AE++
  on both natural images and medical images, demonstrating consistent improvement
  over vanilla ViT-AE and its superiority over other contrastive learning approaches.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: prabhakar24b
month: 0
tex_title: 'ViT-AE++: Improving Vision Transformer Autoencoder for Self-supervised
  Medical Image Representations'
firstpage: 666
lastpage: 679
page: 666-679
order: 666
cycles: false
bibtex_author: Prabhakar, Chinmay and Li, Hongwei and Yang, Jiancheng and Shit, Suprosanna
  and Wiestler, Benedikt and Menze, Bjoern
author:
- given: Chinmay
  family: Prabhakar
- given: Hongwei
  family: Li
- given: Jiancheng
  family: Yang
- given: Suprosanna
  family: Shit
- given: Benedikt
  family: Wiestler
- given: Bjoern
  family: Menze
date: 2024-01-23
address:
container-title: Medical Imaging with Deep Learning
volume: '227'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 23
pdf: https://proceedings.mlr.press/v227/prabhakar24b/prabhakar24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
