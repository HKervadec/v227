---
title: Multi-scale Hierarchical Vision Transformer with Cascaded Attention Decoding
  for Medical Image Segmentation
abstract: Transformers have shown great success in medical image segmentation. However,
  transformers may exhibit a limited generalization ability due to the underlying
  single-scale self-attention (SA) mechanism. In this paper, we address this issue
  by introducing a Multi-scale hiERarchical vIsion Transformer (MERIT) backbone network,
  which improves the generalizability of the model by computing SA at multiple scales.
  We also incorporate an attention-based decoder, namely Cascaded Attention Decoding
  (CASCADE), for further refinement of multi-stage features generated by MERIT. Finally,
  we introduce an effective multi-stage feature mixing loss aggregation (MUTATION)
  method for better model training via implicit ensembling. Our experiments on two
  widely used medical image segmentation benchmarks (i.e., Synapse Multi-organ, ACDC)
  demonstrate the superior performance of MERIT over state-of-the-art methods. Our
  MERIT architecture and MUTATION loss aggregation can be used with downstream medical
  image and semantic segmentation tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rahman24a
month: 0
tex_title: Multi-scale Hierarchical Vision Transformer with Cascaded Attention Decoding
  for Medical Image Segmentation
firstpage: 1526
lastpage: 1544
page: 1526-1544
order: 1526
cycles: false
bibtex_author: Rahman, Md Mostafijur and Marculescu, Radu
author:
- given: Md Mostafijur
  family: Rahman
- given: Radu
  family: Marculescu
date: 2024-01-23
address:
container-title: Medical Imaging with Deep Learning
volume: '227'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 1
  - 23
pdf: https://proceedings.mlr.press/v227/rahman24a/rahman24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
